# SAR-to-Optical Image Translation using CycleGAN

This repository contains an implementation of **CycleGAN** for
translating Synthetic Aperture Radar (SAR) images into optical
(satellite-like) images.\
The project explores how unpaired image-to-image translation can help
visualise SAR data in a more interpretable way.

------------------------------------------------------------------------

## ğŸ“Œ Features

-   CycleGAN implementation with PyTorch.
-   Training and experiment tracking using **MLflow** (integrated with
    **DAGsHub**).\
-   Metrics logging (Cycle Consistency Loss, Identity Loss,
    Discriminator Loss).\
-   Example SAR â†’ Optical translation results.\
-   Support for custom SAR/Optical datasets.

------------------------------------------------------------------------

## ğŸ“‚ Repository Structure

    â”œâ”€â”€ MLFlow_CycleGAN.ipynb    # Training notebook with MLflow integration
    â”œâ”€â”€ results/                 # Output images and evaluation plots
    â”‚   â”œâ”€â”€ cycle_loss.png
    â”‚   â”œâ”€â”€ identity_loss.png
    â”‚   â”œâ”€â”€ train_d_loss.png
    â”‚   â”œâ”€â”€ val_identity_losses.png
    â”‚   â”œâ”€â”€ Results.png
    â”‚   â””â”€â”€ train_g_loss.png
    â””â”€â”€ README.md                # Project documentation

------------------------------------------------------------------------

## ğŸš€ Getting Started

### 1. Clone the repo

``` bash
git clone https://github.com/<your-username>/SAR-to-Optical-CycleGAN.git
cd SAR-to-Optical-CycleGAN
```

### 2. Install dependencies

Make sure you have **Python 3.8+**, PyTorch, and MLflow installed along
with standard libraries like matplotlib, numpy, and pillow.

### 3. Dataset Used

- SAR2OPT dataset

Update dataset paths in the notebook (`MLFlow_CycleGAN.ipynb`) before
training.

### 4. Training

``` bash
jupyter notebook MLFlow_CycleGAN.ipynb
```

All metrics will be tracked automatically with **MLflow**, logged to
**DAGsHub**.

------------------------------------------------------------------------

## ğŸ“Ÿ MLflow + DAGsHub Integration

This project uses **DAGsHub** as the MLflow tracking server.\
To view experiments:

1.  Log in to [DAGsHub](https://dagshub.com).\
2.  Navigate to your project â†’ **Experiments** tab.\
3.  Runs, metrics, and artefacts are synced automatically.

If you want to run MLflow locally as well, use:

``` bash
mlflow ui --host 0.0.0.0 --port 5000
```

Then open <http://localhost:5000> in your browser.

------------------------------------------------------------------------

## ğŸ“Š Training Metrics

### Cycle Consistency Loss

![Cycle Loss](Results/cycle_loss.png)

### Identity Loss

![Identity Loss](Results/identity_loss.png)

### Discriminator Loss

![Discriminator Loss](Results/train_d_loss.png)

### Validation Identity Loss

![Validation Identity Loss](Results/val_identity_losses.png)

------------------------------------------------------------------------

## ğŸ–¼ Example Results

Below are some sample outputs after training (SAR â†’ Generated Optical vs
Real Optical):

![Sample Results](Results/Result.png)

------------------------------------------------------------------------

## ğŸ“ˆ Observations

-   Loss functions show stable convergence over training.\
-   Generated optical images preserve spatial structures from SAR
    inputs.\
-   Model performance improves with higher resolution inputs (512x512).

------------------------------------------------------------------------

## ğŸ”® Future Work

-   Fine-tuning with larger datasets.\
-   Incorporating perceptual loss for better visual realism.\
-   Hosting pre-trained weights for easy inference.

------------------------------------------------------------------------

## ğŸ¤ Contributing

Pull requests are welcome! If you'd like to add features, improve
training, or test on new datasets, feel free to open an issue.

------------------------------------------------------------------------

## ğŸ“œ License

This project is licensed under the MIT License.
